{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# load trained model for visualization\n",
    "cae = load_model('trained_cae.h5')\n",
    "\n",
    "encoder = load_model('trained_encoder.h5')\n",
    "decoder = load_model('trained_decoder.h5')\n",
    "\n",
    "\n",
    "model = cae\n",
    "\n",
    "\n",
    "M = 128\n",
    "L = 5\n",
    "numepochs = 25\n",
    "\n",
    "\n",
    "# One hot encoding\n",
    "rawdata = np.zeros(M)\n",
    "i = 0\n",
    "while(i<M):\n",
    "    rawdata[i] = i\n",
    "    i += 1\n",
    "\n",
    "data = to_categorical(rawdata)\n",
    "#from numpy import reshape\n",
    "data = data.astype(int)\n",
    "ydata = np.reshape(data, (data.shape[0], 1, 1, data.shape[1]))\n",
    "yvaldata = ydata\n",
    "xdata = np.reshape(data, (data.shape[0], 1, 1, data.shape[1]))\n",
    "xvaldata = xdata\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 5, 5, 1)           370001    \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1, 1, 128)         1435136   \n",
      "=================================================================\n",
      "Total params: 1,805,137\n",
      "Trainable params: 1,802,289\n",
      "Non-trainable params: 2,848\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 1, 128)         16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 1, 400)         51600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 400)         1600      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 20, 20, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 1)           2305      \n",
      "=================================================================\n",
      "Total params: 370,001\n",
      "Trainable params: 368,433\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 5, 5, 1)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 20, 20, 1)         0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 20, 20, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 256)       6656      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 6400)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1, 128)         16512     \n",
      "=================================================================\n",
      "Total params: 1,435,136\n",
      "Trainable params: 1,433,856\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class_idx = ydata[0]\n",
    "#indices = y_test[:, 0]\n",
    "#indices = np.where(ydata[:, class_idx] == 1.)[0]\n",
    "indices = ydata\n",
    "\n",
    "idx = ydata[0]\n",
    "#idx = indices[0]\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (128, 6)\n",
    "#plt.imshow(idx[:])\n",
    "model.summary()\n",
    "model.layers[1].summary()\n",
    "model.layers[2].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activations = encoder.predict(xdata)\n",
    "#print(activations[0])\n",
    "#print(activations[0])\n",
    "inp = xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = np.sqrt(M)\n",
    "if (np.mod(dim1, 1) == 0):\n",
    "    dim2 = dim1\n",
    "else:\n",
    "    dim1 = np.sqrt(M/2)\n",
    "    dim2 = M/dim1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "layer_idx = utils.find_layer_idx(model.layers[2], 'conv2d_2')\n",
    "print(layer_idx)\n",
    "model.layers[-1].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer model_2 has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `get_input_at(node_index)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ffe7f299788d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'guided'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 grads = visualize_saliency(model.layers[model_num], layer_idx, filter_indices=None, \n\u001b[1;32m---> 16\u001b[1;33m                                            seed_input=inp, backprop_modifier=modifier)\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodifier\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mmodifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'vanilla'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonGPU\\lib\\site-packages\\vis\\visualization\\saliency.py\u001b[0m in \u001b[0;36mvisualize_saliency\u001b[1;34m(model, layer_idx, filter_indices, seed_input, wrt_tensor, backprop_modifier, grad_modifier, keepdims)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mActivationMaximization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     ]\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvisualize_saliency_with_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrt_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonGPU\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36minput\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[1;32m--> 784\u001b[1;33m                                  \u001b[1;34m' has multiple inbound nodes, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m                                  \u001b[1;34m'hence the notion of \"layer input\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                                  \u001b[1;34m'is ill-defined. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer model_2 has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `get_input_at(node_index)` instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index in [0]:  \n",
    "    for model_num in [1, 2]:\n",
    "        for layer_idx in np.arange(10):\n",
    "            activations = encoder.predict(xdata)\n",
    "            #print(activations[0])\n",
    "            #print(activations[index])\n",
    "            inp = activations[index]\n",
    "\n",
    "            f, ax = plt.subplots(1, 4)\n",
    "            # displays input\n",
    "            ax[0].set_title(model.layers[model_num].layers[layer_idx].name + ' ' + str(index))\n",
    "            ax[0].imshow(inp[:, ..., 0], cmap='binary')\n",
    "\n",
    "            for i, modifier in enumerate([None, 'guided', 'relu']):\n",
    "                grads = visualize_saliency(model.layers[model_num], layer_idx, filter_indices=None, \n",
    "                                           seed_input=inp, backprop_modifier=modifier)\n",
    "                if modifier is None:\n",
    "                    modifier = 'vanilla'\n",
    "                ax[i+1].set_title(modifier)    \n",
    "                ax[i+1].imshow(grads, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
